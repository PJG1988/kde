From patchwork Tue Nov  5 19:19:07 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Aaron Lewis <aaronlewis@google.com>
X-Patchwork-Id: 11228441
Return-Path: <SRS0=X2oT=Y5=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 2EB081515
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue,  5 Nov 2019 19:19:20 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 1700921928
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue,  5 Nov 2019 19:19:20 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (2048-bit key) header.d=google.com header.i=@google.com
 header.b="fxRm2S13"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S2390865AbfKETTT (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Tue, 5 Nov 2019 14:19:19 -0500
Received: from mail-pl1-f202.google.com ([209.85.214.202]:51978 "EHLO
        mail-pl1-f202.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S2390846AbfKETTT (ORCPT <rfc822;kvm@vger.kernel.org>);
        Tue, 5 Nov 2019 14:19:19 -0500
Received: by mail-pl1-f202.google.com with SMTP id h7so8752092pll.18
        for <kvm@vger.kernel.org>; Tue, 05 Nov 2019 11:19:18 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:in-reply-to:message-id:mime-version:references:subject:from:to
         :cc;
        bh=zuF7sKZCPT+TK1RMBRSi/baQpV2Rh8fSC5oFHVCBvvc=;
        b=fxRm2S13cZxdOTIxyNOX/QX1BC3mC1jd1AMzjYxWmsN8JVfMmr5CP49gwlzXCU6q/T
         i08VeQ1tm9bObGKhWQvtZiGFSJQI4L8+lkAbQzTecRmB1y9jJEWb7EeBwyEUtG/lYi4c
         589gPdN6JGID9VFgompDh/r1cg8edoX2/1JHpTjHr039iGBpoON9rjFkrIU7P4Bo7AGm
         LU9gH8mLPQYzphKZpqAcymmsuHAv7udPXKH579lfWtARxY3kLnV0VQCSaxJzXIyCscIp
         eMu3BbbC03rHbkpqqKqAAdtFq7e1SZDFufUkDYCu7igGbC/L3YUByty572pSg/PRV+Ly
         NQOQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:in-reply-to:message-id:mime-version
         :references:subject:from:to:cc;
        bh=zuF7sKZCPT+TK1RMBRSi/baQpV2Rh8fSC5oFHVCBvvc=;
        b=lxlA3vKT4V8YL7B9fpmUE7irpdPlLwC/13IU0gV5o/j2Y1DIFPfwdx3AeE46HfzGZB
         +lfiU++aUzg3OitB9V1q4Z5RM9ph8lkAQ9YDaJHl6BJv0AkxS9eZw46ra0C8pA249D3p
         m2cPVm5rs8NITrA0TLP/06yP2IuIGnHcBpHbCTo2wc2nlH9H/xsnwjSQyFuD7QuiBwCV
         AauGog6MxyvJ5nXjZbWnUznVQDDh7reS+u0DvY4hBh43Ir2UkvI6VGaadXUD8jqhePqk
         wFbElxMrMF2sfpiN6vawg518RWeoPc6ljonEiPobiJ4OBUV6xCFPKqLbGzOsfEBSgBv4
         FjiQ==
X-Gm-Message-State: APjAAAXNDJBkDV0JTPm2J5xIs5/8EI+q1LxW67arFb9VCyNj4ncuUbCV
        pxKXaIxT65ib14VSRRKjiBP+/95vsxMxcQLZdcdiY3jSLr0iNIiSzBUdlgldYtaZOl6JyQgKc1I
        OEUsthvskwjVYB8ZOCmA5B7lE89jlgzztzC0aJsmHPTj6Yh1eBGZJJ9KXk/J04As4gv5u
X-Google-Smtp-Source: 
 APXvYqzcPLdhfbgNu8QkgzNk9uVEb7eZdeeZ16LOp9wb1vAHAgFnP7+7QePdZNT9XSkCU+4dIo+tGQ70f7UiC//G
X-Received: by 2002:a63:d44a:: with SMTP id
 i10mr38553263pgj.105.1572981557994;
 Tue, 05 Nov 2019 11:19:17 -0800 (PST)
Date: Tue,  5 Nov 2019 11:19:07 -0800
In-Reply-To: <20191105191910.56505-1-aaronlewis@google.com>
Message-Id: <20191105191910.56505-2-aaronlewis@google.com>
Mime-Version: 1.0
References: <20191105191910.56505-1-aaronlewis@google.com>
X-Mailer: git-send-email 2.24.0.rc1.363.gb1bccd3e3d-goog
Subject: [PATCH v2 1/4] kvm: nested: Introduce read_and_check_msr_entry()
From: Aaron Lewis <aaronlewis@google.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>,
        Jim Mattson <jmattson@google.com>,
        Aaron Lewis <aaronlewis@google.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

Add the function read_and_check_msr_entry() which just pulls some code
out of nested_vmx_store_msr() for now, however, this is in preparation
for a change later in this series were we reuse the code in
read_and_check_msr_entry().

Reviewed-by: Jim Mattson <jmattson@google.com>
Signed-off-by: Aaron Lewis <aaronlewis@google.com>
Reviewed-by: Liran Alon <liran.alon@oracle.com>
---
 arch/x86/kvm/vmx/nested.c | 35 ++++++++++++++++++++++-------------
 1 file changed, 22 insertions(+), 13 deletions(-)

--
2.24.0.rc1.363.gb1bccd3e3d-goog

diff --git a/arch/x86/kvm/vmx/nested.c b/arch/x86/kvm/vmx/nested.c
index e76eb4f07f6c..7b058d7b9fcc 100644
--- a/arch/x86/kvm/vmx/nested.c
+++ b/arch/x86/kvm/vmx/nested.c
@@ -929,6 +929,26 @@ static u32 nested_vmx_load_msr(struct kvm_vcpu *vcpu, u64 gpa, u32 count)
 	return i + 1;
 }

+static bool read_and_check_msr_entry(struct kvm_vcpu *vcpu, u64 gpa, int i,
+				     struct vmx_msr_entry *e)
+{
+	if (kvm_vcpu_read_guest(vcpu,
+				gpa + i * sizeof(*e),
+				e, 2 * sizeof(u32))) {
+		pr_debug_ratelimited(
+			"%s cannot read MSR entry (%u, 0x%08llx)\n",
+			__func__, i, gpa + i * sizeof(*e));
+		return false;
+	}
+	if (nested_vmx_store_msr_check(vcpu, e)) {
+		pr_debug_ratelimited(
+			"%s check failed (%u, 0x%x, 0x%x)\n",
+			__func__, i, e->index, e->reserved);
+		return false;
+	}
+	return true;
+}
+
 static int nested_vmx_store_msr(struct kvm_vcpu *vcpu, u64 gpa, u32 count)
 {
 	u64 data;
@@ -940,20 +960,9 @@ static int nested_vmx_store_msr(struct kvm_vcpu *vcpu, u64 gpa, u32 count)
 		if (unlikely(i >= max_msr_list_size))
 			return -EINVAL;

-		if (kvm_vcpu_read_guest(vcpu,
-					gpa + i * sizeof(e),
-					&e, 2 * sizeof(u32))) {
-			pr_debug_ratelimited(
-				"%s cannot read MSR entry (%u, 0x%08llx)\n",
-				__func__, i, gpa + i * sizeof(e));
+		if (!read_and_check_msr_entry(vcpu, gpa, i, &e))
 			return -EINVAL;
-		}
-		if (nested_vmx_store_msr_check(vcpu, &e)) {
-			pr_debug_ratelimited(
-				"%s check failed (%u, 0x%x, 0x%x)\n",
-				__func__, i, e.index, e.reserved);
-			return -EINVAL;
-		}
+
 		if (kvm_get_msr(vcpu, e.index, &data)) {
 			pr_debug_ratelimited(
 				"%s cannot read MSR (%u, 0x%x)\n",

From patchwork Tue Nov  5 19:19:08 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Aaron Lewis <aaronlewis@google.com>
X-Patchwork-Id: 11228443
Return-Path: <SRS0=X2oT=Y5=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 45CE314E5
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue,  5 Nov 2019 19:19:23 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 2F67B214B2
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue,  5 Nov 2019 19:19:23 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (2048-bit key) header.d=google.com header.i=@google.com
 header.b="S3gsOIZ4"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S2390884AbfKETTW (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Tue, 5 Nov 2019 14:19:22 -0500
Received: from mail-pg1-f202.google.com ([209.85.215.202]:48640 "EHLO
        mail-pg1-f202.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S2390878AbfKETTW (ORCPT <rfc822;kvm@vger.kernel.org>);
        Tue, 5 Nov 2019 14:19:22 -0500
Received: by mail-pg1-f202.google.com with SMTP id q20so3148938pgj.15
        for <kvm@vger.kernel.org>; Tue, 05 Nov 2019 11:19:21 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:in-reply-to:message-id:mime-version:references:subject:from:to
         :cc;
        bh=X4a0tiRiKuTwKKaD0bjI7X4v1uWCRl+63mSdCrFaD3o=;
        b=S3gsOIZ4mwIwfT/aWElNMrK7SlnI2g3LRc2mURyIe5osjKIj9CdbiYh6lJg83ZSCjj
         7C46t/MrCW6pUoySNRPvP8QtkEXYGHhjMfWWqQS+yO2KuCgSTS3hrc+Z1Km118pFqV3b
         8/7WGMRb+DPpJBQ4K7k1LdR566nYaUidYt00aoaUzAFD6Kh5kXw7pUf6LIiZoGQFP+6T
         J3WGzsrWOHC5r33LvS+gRfUF0m8sxwHU41YyKBZ9CpZTi6/pj84hBlZRgoSmmTDLc6N7
         A4DY6XlwFqDbPU3oVF32qNHHGxj3ARxdkx5DN6ZEyaL8KJLwbwmQH/TjaRH6+6mS5Ue6
         Db1w==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:in-reply-to:message-id:mime-version
         :references:subject:from:to:cc;
        bh=X4a0tiRiKuTwKKaD0bjI7X4v1uWCRl+63mSdCrFaD3o=;
        b=NkRfNiCbdV7KEKIDDDR2iQuRmVK+d90lB+5Jvt8xbvZyik4sLbET5H6exRgAtPhVAs
         vNHZgbcJdc2M46teSEQ+KtAfSLMDgE5V6lATdwqq37m2Ox/QayTCxOmXTcgxzywE9iUh
         djxk83eqiZzaZsw4cLGL1KmOUfBF7SPqHIxvCmNJa3HY2/cRzkTRihDCMLZUNNvmdW6F
         s3r7BlpW94oood5/3ebtRw2Mtw5C5KfX0tbB9GpKRqyysJtMIM1345+lEZ6+S/yzPGz0
         bZVWT0GQo33Izz0YvwpvuNkhQqNo2c6s6UMiLWpHg2zVMSLU59mgeOsCCJVCjOXkp8aT
         znyA==
X-Gm-Message-State: APjAAAV94fZeeBeSJf+QGzHkHXdfT3JSUCG3WBaZuh2Ik+fKKY8KqlIi
        F/jZKF3JVu3gf7XohpDzxsN44p2rnVkwxIYVq6VL26OEJUoJO35ov8ZM5ineoc7ngtERuaxAP6e
        ltTtWRxtgaXoBu+laXgFjOqHGNEgTFrWqjv6vprbiwcqu7EnjXKrGet7wL2bfgyjkfNoU
X-Google-Smtp-Source: 
 APXvYqxVHB4CibG2BC67DF5gtVqqdR4T94SOstC30L4fy5eHku08KEoRBT3GJll08NianydNouoFVl8nAltdFLlD
X-Received: by 2002:a63:c411:: with SMTP id
 h17mr16151703pgd.360.1572981561121;
 Tue, 05 Nov 2019 11:19:21 -0800 (PST)
Date: Tue,  5 Nov 2019 11:19:08 -0800
In-Reply-To: <20191105191910.56505-1-aaronlewis@google.com>
Message-Id: <20191105191910.56505-3-aaronlewis@google.com>
Mime-Version: 1.0
References: <20191105191910.56505-1-aaronlewis@google.com>
X-Mailer: git-send-email 2.24.0.rc1.363.gb1bccd3e3d-goog
Subject: [PATCH v2 2/4] kvm: vmx: Rename NR_AUTOLOAD_MSRS to NR_MSR_ENTRIES
From: Aaron Lewis <aaronlewis@google.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>,
        Jim Mattson <jmattson@google.com>,
        Aaron Lewis <aaronlewis@google.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

Rename NR_AUTOLOAD_MSRS to NR_MSR_ENTRIES.  This needs to be done
due to the addition of the MSR-autostore area that will be added later
in this series.  After that the name AUTOLOAD will no longer make sense.

Reviewed-by: Jim Mattson <jmattson@google.com>
Signed-off-by: Aaron Lewis <aaronlewis@google.com>
---
 arch/x86/kvm/vmx/vmx.c | 4 ++--
 arch/x86/kvm/vmx/vmx.h | 4 ++--
 2 files changed, 4 insertions(+), 4 deletions(-)

--
2.24.0.rc1.363.gb1bccd3e3d-goog

diff --git a/arch/x86/kvm/vmx/vmx.c b/arch/x86/kvm/vmx/vmx.c
index e7970a2e8eae..c0160ca9ddba 100644
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@ -940,8 +940,8 @@ static void add_atomic_switch_msr(struct vcpu_vmx *vmx, unsigned msr,
 	if (!entry_only)
 		j = find_msr(&m->host, msr);

-	if ((i < 0 && m->guest.nr == NR_AUTOLOAD_MSRS) ||
-		(j < 0 &&  m->host.nr == NR_AUTOLOAD_MSRS)) {
+	if ((i < 0 && m->guest.nr == NR_MSR_ENTRIES) ||
+		(j < 0 &&  m->host.nr == NR_MSR_ENTRIES)) {
 		printk_once(KERN_WARNING "Not enough msr switch entries. "
 				"Can't add msr %x\n", msr);
 		return;
diff --git a/arch/x86/kvm/vmx/vmx.h b/arch/x86/kvm/vmx/vmx.h
index bee16687dc0b..0c6835bd6945 100644
--- a/arch/x86/kvm/vmx/vmx.h
+++ b/arch/x86/kvm/vmx/vmx.h
@@ -22,11 +22,11 @@ extern u32 get_umwait_control_msr(void);

 #define X2APIC_MSR(r) (APIC_BASE_MSR + ((r) >> 4))

-#define NR_AUTOLOAD_MSRS 8
+#define NR_MSR_ENTRIES 8

 struct vmx_msrs {
 	unsigned int		nr;
-	struct vmx_msr_entry	val[NR_AUTOLOAD_MSRS];
+	struct vmx_msr_entry	val[NR_MSR_ENTRIES];
 };

 struct shared_msr_entry {

From patchwork Tue Nov  5 19:19:09 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Aaron Lewis <aaronlewis@google.com>
X-Patchwork-Id: 11228445
Return-Path: <SRS0=X2oT=Y5=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 7CA461515
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue,  5 Nov 2019 19:19:26 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 66485214B2
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue,  5 Nov 2019 19:19:26 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (2048-bit key) header.d=google.com header.i=@google.com
 header.b="L+p2IPhM"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S2390918AbfKETTZ (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Tue, 5 Nov 2019 14:19:25 -0500
Received: from mail-pf1-f201.google.com ([209.85.210.201]:50264 "EHLO
        mail-pf1-f201.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S2390734AbfKETTZ (ORCPT <rfc822;kvm@vger.kernel.org>);
        Tue, 5 Nov 2019 14:19:25 -0500
Received: by mail-pf1-f201.google.com with SMTP id e13so10300434pff.17
        for <kvm@vger.kernel.org>; Tue, 05 Nov 2019 11:19:24 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:in-reply-to:message-id:mime-version:references:subject:from:to
         :cc;
        bh=TuG0A8jvRSo3LdFh+fwDlIO3wYLZ26Y3Enhbcv1wzSc=;
        b=L+p2IPhMc/CuEoQeau8+9HcKWghhivmtRQkx227Sp+mC4p+gWr/2U8N8tgFqNhjnoY
         7e9EETNlOx48gdCqUPAegbIB7uK2BpOLshoNyZqwOBNvllJITxAllKR7Z9zKF39iAHqr
         iFNqhc7Fi6TZixLA0ysEt+ee/BAbD/zvbHI7Zcnes6RAoV1oIL9858OJtxkdWEQtzHOS
         JB3bw2ykLiXQWHwQvNI6cTxxDiYP1Xl3nmOzINWzljqFVrdFn9a0hhF6v0BOnhQvZvSc
         WZrTy9+IJpv3U9z9VjsZIR0U/1jRl1yTtHXJ8Rj9foSTeDnPs/SxGfHczkxmTd1+pExf
         +cSw==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:in-reply-to:message-id:mime-version
         :references:subject:from:to:cc;
        bh=TuG0A8jvRSo3LdFh+fwDlIO3wYLZ26Y3Enhbcv1wzSc=;
        b=hNpYeRfrmn4SwvhqX4agP3wQWez9IrZq1pl42wwcltu97ATv3VWUIFOlsNW52+LOJU
         IHW+Bibds0f6vjYyKe+oJ3HF7vwj8RLw+3FK1mK+BfTvv1vHg8gD4479QwhvmWqY6qF6
         IOIgetv3pq47TdULNx7r2ZWfDeIWkek1QuXFPzdgPQCyvutMLyIyUmfMH+ZFGkY7Is93
         8SzIq1r7tfUJwfnFQ5lMio0xE8AbVZn4NaTnlaA2LmVqLyrWvrrTyNckXWr7ELwoV+eO
         DAsrus5QD6H58VEGlbR6jfZAARsQiI9tEtiSntQvNTW5EhNkVAZwtDBZnv8xorgSgt72
         EahQ==
X-Gm-Message-State: APjAAAWsk0f9kbm3MgUNw7FTjt715eSbljQw1UyAmA8/8l+YGfkw5V1k
        Q/gmjoRMVlpWo9jW8FkZNoV5x/ZskE6T9x7wtj4cUz9LL6F9fE0LXbSOlhzru9ZZvBIgkouJTSM
        1XyiVnRJZIFQ0aV4WpyReeXJnLsHkGp50rrkBfSFAWJDg+1wYZOEZnd3PsY2oHhdU0hWl
X-Google-Smtp-Source: 
 APXvYqz2Y7jD3D2oew2/uCVZDH2j+7Y7S8f+yBI7jI5SRWP4IHlOXHArPebVcERnwzv16eJpCwxuITI1OBJSEjQB
X-Received: by 2002:a63:5125:: with SMTP id f37mr36470721pgb.98.1572981563945;
 Tue, 05 Nov 2019 11:19:23 -0800 (PST)
Date: Tue,  5 Nov 2019 11:19:09 -0800
In-Reply-To: <20191105191910.56505-1-aaronlewis@google.com>
Message-Id: <20191105191910.56505-4-aaronlewis@google.com>
Mime-Version: 1.0
References: <20191105191910.56505-1-aaronlewis@google.com>
X-Mailer: git-send-email 2.24.0.rc1.363.gb1bccd3e3d-goog
Subject: [PATCH v2 3/4] kvm: vmx: Rename function find_msr() to
 vmx_find_msr_index()
From: Aaron Lewis <aaronlewis@google.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>,
        Jim Mattson <jmattson@google.com>,
        Aaron Lewis <aaronlewis@google.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

Rename function find_msr() to vmx_find_msr_index() to share
implementations between vmx.c and nested.c in an upcoming change.

Reviewed-by: Jim Mattson <jmattson@google.com>
Signed-off-by: Aaron Lewis <aaronlewis@google.com>
---
 arch/x86/kvm/vmx/vmx.c | 10 +++++-----
 arch/x86/kvm/vmx/vmx.h |  1 +
 2 files changed, 6 insertions(+), 5 deletions(-)

--
2.24.0.rc1.363.gb1bccd3e3d-goog

diff --git a/arch/x86/kvm/vmx/vmx.c b/arch/x86/kvm/vmx/vmx.c
index c0160ca9ddba..39c701730297 100644
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@ -835,7 +835,7 @@ static void clear_atomic_switch_msr_special(struct vcpu_vmx *vmx,
 	vm_exit_controls_clearbit(vmx, exit);
 }

-static int find_msr(struct vmx_msrs *m, unsigned int msr)
+int vmx_find_msr_index(struct vmx_msrs *m, u32 msr)
 {
 	unsigned int i;

@@ -869,7 +869,7 @@ static void clear_atomic_switch_msr(struct vcpu_vmx *vmx, unsigned msr)
 		}
 		break;
 	}
-	i = find_msr(&m->guest, msr);
+	i = vmx_find_msr_index(&m->guest, msr);
 	if (i < 0)
 		goto skip_guest;
 	--m->guest.nr;
@@ -877,7 +877,7 @@ static void clear_atomic_switch_msr(struct vcpu_vmx *vmx, unsigned msr)
 	vmcs_write32(VM_ENTRY_MSR_LOAD_COUNT, m->guest.nr);

 skip_guest:
-	i = find_msr(&m->host, msr);
+	i = vmx_find_msr_index(&m->host, msr);
 	if (i < 0)
 		return;

@@ -936,9 +936,9 @@ static void add_atomic_switch_msr(struct vcpu_vmx *vmx, unsigned msr,
 		wrmsrl(MSR_IA32_PEBS_ENABLE, 0);
 	}

-	i = find_msr(&m->guest, msr);
+	i = vmx_find_msr_index(&m->guest, msr);
 	if (!entry_only)
-		j = find_msr(&m->host, msr);
+		j = vmx_find_msr_index(&m->host, msr);

 	if ((i < 0 && m->guest.nr == NR_MSR_ENTRIES) ||
 		(j < 0 &&  m->host.nr == NR_MSR_ENTRIES)) {
diff --git a/arch/x86/kvm/vmx/vmx.h b/arch/x86/kvm/vmx/vmx.h
index 0c6835bd6945..34b5fef603d8 100644
--- a/arch/x86/kvm/vmx/vmx.h
+++ b/arch/x86/kvm/vmx/vmx.h
@@ -334,6 +334,7 @@ void vmx_set_virtual_apic_mode(struct kvm_vcpu *vcpu);
 struct shared_msr_entry *find_msr_entry(struct vcpu_vmx *vmx, u32 msr);
 void pt_update_intercept_for_msr(struct vcpu_vmx *vmx);
 void vmx_update_host_rsp(struct vcpu_vmx *vmx, unsigned long host_rsp);
+int vmx_find_msr_index(struct vmx_msrs *m, u32 msr);

 #define POSTED_INTR_ON  0
 #define POSTED_INTR_SN  1

From patchwork Tue Nov  5 19:19:10 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Aaron Lewis <aaronlewis@google.com>
X-Patchwork-Id: 11228447
Return-Path: <SRS0=X2oT=Y5=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 6AC171515
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue,  5 Nov 2019 19:19:29 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 4B29B21929
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue,  5 Nov 2019 19:19:29 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (2048-bit key) header.d=google.com header.i=@google.com
 header.b="JlVGq/zG"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S2403756AbfKETT2 (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Tue, 5 Nov 2019 14:19:28 -0500
Received: from mail-vs1-f74.google.com ([209.85.217.74]:44452 "EHLO
        mail-vs1-f74.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S2390734AbfKETT2 (ORCPT <rfc822;kvm@vger.kernel.org>);
        Tue, 5 Nov 2019 14:19:28 -0500
Received: by mail-vs1-f74.google.com with SMTP id d75so3617793vsc.11
        for <kvm@vger.kernel.org>; Tue, 05 Nov 2019 11:19:27 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:in-reply-to:message-id:mime-version:references:subject:from:to
         :cc;
        bh=TCMHo2rdlOpxl/wt7piVn2IQvOGL4FMZMET/QQNUf0g=;
        b=JlVGq/zGS3c0tKx/52+/t4qsxHROuyJigTCCBnbBSHxwPj7zeRQ99nAGiO2KTt5AtS
         8i/2HKrDM2vmUaIfH5JX6cAZzNiRdejtSC5tZMA4KqlwuaSDX/mxEcznTQK3CSSFQJJj
         rP48HjD9L7qI7jnCEgYYV2RsPVPsFalXa1JuUf9FZrJauztr6d8CIhP8BWrB3S3wr6q9
         9qmjIpLHzOZYyRivWD6LkGLrmShHvse84eS2mSQHxsS9qyiA3yaOCRVu4HdOL7x5pCqx
         Pu1fIIOl7X/xZtQQrNJ9CUy13TW72p5gjnU6WEdH6Rr3pS7ElBSILehguPBfYM3a7Jis
         8wqw==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:in-reply-to:message-id:mime-version
         :references:subject:from:to:cc;
        bh=TCMHo2rdlOpxl/wt7piVn2IQvOGL4FMZMET/QQNUf0g=;
        b=K2aknb3sxFcVfjIfaLytmpdi2Rr8KonqpARGWxFax/4jtscdodf5/Ot+oSYoG9KxHq
         P2DT6aXWAQmeh0yK6AoSvzzpHEDP7Wa0dLq0PSkA+uB+tp07wiSLRU1bv5ibcn5DnY5s
         X+ComlB0X6Vdx79BjBliUwKxQzWTkL1XbKwU9+0KL+h+0azoaTHY4fSmvw2FCQ2PMyLA
         v7FveLLA1JLHJgwyxrYRCR2wGXCWsC7CnKQftgxxIF5ukLTMtbLJdhZ9mRZaf7eSY2j/
         amfz1XTej6SAntN2rwECVbwYv7qtXFcbOl4RV205XcCNJTZScuerxfPF6Uk2XUpTHtTY
         IFiw==
X-Gm-Message-State: APjAAAVrjZF+RECnntUCoRAvgKNdtRFcO8QKSjLhTPBjBDXsi1NgMH/Q
        x7cGgfDcP0kPlJrXA31xOkeQQnCWiK/vpw2DXW5B2XqbIw/kJw4zp55GhD1F3fwSRwit+4CxxFe
        8QmErj0YhLwnnxOBSGANS6o/gf9z9q9i+Rrkyh6CqSF3giKgmI+D4CdycQJsGmVtCczur
X-Google-Smtp-Source: 
 APXvYqzVpD6lniCigiePR3BVCOyzMZhWmj0+NYcMJ2thkorl9cGHmiZQQ5Yzj2/2TuAUJRqPsRXHsv6fKDhc3wFA
X-Received: by 2002:a05:6102:1d2:: with SMTP id
 s18mr7455447vsq.197.1572981566872;
 Tue, 05 Nov 2019 11:19:26 -0800 (PST)
Date: Tue,  5 Nov 2019 11:19:10 -0800
In-Reply-To: <20191105191910.56505-1-aaronlewis@google.com>
Message-Id: <20191105191910.56505-5-aaronlewis@google.com>
Mime-Version: 1.0
References: <20191105191910.56505-1-aaronlewis@google.com>
X-Mailer: git-send-email 2.24.0.rc1.363.gb1bccd3e3d-goog
Subject: [PATCH v2 4/4] KVM: nVMX: Add support for capturing highest
 observable L2 TSC
From: Aaron Lewis <aaronlewis@google.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>,
        Jim Mattson <jmattson@google.com>,
        Aaron Lewis <aaronlewis@google.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

The L1 hypervisor may include the IA32_TIME_STAMP_COUNTER MSR in the
vmcs12 MSR VM-exit MSR-store area as a way of determining the highest
TSC value that might have been observed by L2 prior to VM-exit. The
current implementation does not capture a very tight bound on this
value.  To tighten the bound, add the IA32_TIME_STAMP_COUNTER MSR to the
vmcs02 VM-exit MSR-store area whenever it appears in the vmcs12 VM-exit
MSR-store area.  When L0 processes the vmcs12 VM-exit MSR-store area
during the emulation of an L2->L1 VM-exit, special-case the
IA32_TIME_STAMP_COUNTER MSR, using the value stored in the vmcs02
VM-exit MSR-store area to derive the value to be stored in the vmcs12
VM-exit MSR-store area.

Reviewed-by: Jim Mattson <jmattson@google.com>
Signed-off-by: Aaron Lewis <aaronlewis@google.com>
Reviewed-by: Liran Alon <liran.alon@oracle.com>
---
 arch/x86/kvm/vmx/nested.c | 92 ++++++++++++++++++++++++++++++++++++---
 arch/x86/kvm/vmx/vmx.h    |  4 ++
 2 files changed, 90 insertions(+), 6 deletions(-)

--
2.24.0.rc1.363.gb1bccd3e3d-goog

diff --git a/arch/x86/kvm/vmx/nested.c b/arch/x86/kvm/vmx/nested.c
index 7b058d7b9fcc..cb2a92341eab 100644
--- a/arch/x86/kvm/vmx/nested.c
+++ b/arch/x86/kvm/vmx/nested.c
@@ -929,6 +929,37 @@ static u32 nested_vmx_load_msr(struct kvm_vcpu *vcpu, u64 gpa, u32 count)
 	return i + 1;
 }

+static bool nested_vmx_get_vmexit_msr_value(struct kvm_vcpu *vcpu,
+					    u32 msr_index,
+					    u64 *data)
+{
+	struct vcpu_vmx *vmx = to_vmx(vcpu);
+
+	/*
+	 * If the L0 hypervisor stored a more accurate value for the TSC that
+	 * does not include the time taken for emulation of the L2->L1
+	 * VM-exit in L0, use the more accurate value.
+	 */
+	if (msr_index == MSR_IA32_TSC) {
+		int index = vmx_find_msr_index(&vmx->msr_autostore.guest,
+					       MSR_IA32_TSC);
+
+		if (index >= 0) {
+			u64 val = vmx->msr_autostore.guest.val[index].value;
+
+			*data = kvm_read_l1_tsc(vcpu, val);
+			return true;
+		}
+	}
+
+	if (kvm_get_msr(vcpu, msr_index, data)) {
+		pr_debug_ratelimited("%s cannot read MSR (0x%x)\n", __func__,
+			msr_index);
+		return false;
+	}
+	return true;
+}
+
 static bool read_and_check_msr_entry(struct kvm_vcpu *vcpu, u64 gpa, int i,
 				     struct vmx_msr_entry *e)
 {
@@ -963,12 +994,9 @@ static int nested_vmx_store_msr(struct kvm_vcpu *vcpu, u64 gpa, u32 count)
 		if (!read_and_check_msr_entry(vcpu, gpa, i, &e))
 			return -EINVAL;

-		if (kvm_get_msr(vcpu, e.index, &data)) {
-			pr_debug_ratelimited(
-				"%s cannot read MSR (%u, 0x%x)\n",
-				__func__, i, e.index);
+		if (!nested_vmx_get_vmexit_msr_value(vcpu, e.index, &data))
 			return -EINVAL;
-		}
+
 		if (kvm_vcpu_write_guest(vcpu,
 					 gpa + i * sizeof(e) +
 					     offsetof(struct vmx_msr_entry, value),
@@ -982,6 +1010,51 @@ static int nested_vmx_store_msr(struct kvm_vcpu *vcpu, u64 gpa, u32 count)
 	return 0;
 }

+static bool nested_msr_store_list_has_msr(struct kvm_vcpu *vcpu, u32 msr_index)
+{
+	struct vmcs12 *vmcs12 = get_vmcs12(vcpu);
+	u32 count = vmcs12->vm_exit_msr_store_count;
+	u64 gpa = vmcs12->vm_exit_msr_store_addr;
+	struct vmx_msr_entry e;
+	u32 i;
+
+	for (i = 0; i < count; i++) {
+		if (!read_and_check_msr_entry(vcpu, gpa, i, &e))
+			return false;
+
+		if (e.index == msr_index)
+			return true;
+	}
+	return false;
+}
+
+static void prepare_vmx_msr_autostore_list(struct kvm_vcpu *vcpu,
+					   u32 msr_index)
+{
+	struct vcpu_vmx *vmx = to_vmx(vcpu);
+	struct vmx_msrs *autostore = &vmx->msr_autostore.guest;
+	int i = vmx_find_msr_index(autostore, msr_index);
+	bool in_autostore_list = i >= 0;
+	bool in_vmcs12_store_list;
+	int last;
+
+	in_vmcs12_store_list = nested_msr_store_list_has_msr(vcpu, msr_index);
+
+	if (in_vmcs12_store_list && !in_autostore_list) {
+		if (autostore->nr == NR_MSR_ENTRIES) {
+			pr_warn_ratelimited(
+				"Not enough msr entries in msr_autostore.  Can't add msr %x\n",
+				msr_index);
+			return;
+		}
+		last = autostore->nr++;
+		autostore->val[last].index = msr_index;
+	} else if (!in_vmcs12_store_list && in_autostore_list) {
+		last = --autostore->nr;
+		autostore->val[i] = autostore->val[last];
+	}
+}
+
 static bool nested_cr3_valid(struct kvm_vcpu *vcpu, unsigned long val)
 {
 	unsigned long invalid_mask;
@@ -2027,7 +2100,7 @@ static void prepare_vmcs02_constant_state(struct vcpu_vmx *vmx)
 	 * addresses are constant (for vmcs02), the counts can change based
 	 * on L2's behavior, e.g. switching to/from long mode.
 	 */
-	vmcs_write32(VM_EXIT_MSR_STORE_COUNT, 0);
+	vmcs_write64(VM_EXIT_MSR_STORE_ADDR, __pa(vmx->msr_autostore.guest.val));
 	vmcs_write64(VM_EXIT_MSR_LOAD_ADDR, __pa(vmx->msr_autoload.host.val));
 	vmcs_write64(VM_ENTRY_MSR_LOAD_ADDR, __pa(vmx->msr_autoload.guest.val));

@@ -2294,6 +2367,13 @@ static void prepare_vmcs02_rare(struct vcpu_vmx *vmx, struct vmcs12 *vmcs12)
 		vmcs_write64(EOI_EXIT_BITMAP3, vmcs12->eoi_exit_bitmap3);
 	}

+	/*
+	 * Make sure the msr_autostore list is up to date before we set the
+	 * count in the vmcs02.
+	 */
+	prepare_vmx_msr_autostore_list(&vmx->vcpu, MSR_IA32_TSC);
+
+	vmcs_write32(VM_EXIT_MSR_STORE_COUNT, vmx->msr_autostore.guest.nr);
 	vmcs_write32(VM_EXIT_MSR_LOAD_COUNT, vmx->msr_autoload.host.nr);
 	vmcs_write32(VM_ENTRY_MSR_LOAD_COUNT, vmx->msr_autoload.guest.nr);

diff --git a/arch/x86/kvm/vmx/vmx.h b/arch/x86/kvm/vmx/vmx.h
index 34b5fef603d8..0ab1562287af 100644
--- a/arch/x86/kvm/vmx/vmx.h
+++ b/arch/x86/kvm/vmx/vmx.h
@@ -230,6 +230,10 @@ struct vcpu_vmx {
 		struct vmx_msrs host;
 	} msr_autoload;

+	struct msr_autostore {
+		struct vmx_msrs guest;
+	} msr_autostore;
+
 	struct {
 		int vm86_active;
 		ulong save_rflags;
