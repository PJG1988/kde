From patchwork Fri Nov  8 05:14:36 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Aaron Lewis <aaronlewis@google.com>
X-Patchwork-Id: 11234093
Return-Path: <SRS0=CHcm=ZA=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 0A3C1139A
	for <patchwork-kvm@patchwork.kernel.org>;
 Fri,  8 Nov 2019 05:14:50 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id DC82821848
	for <patchwork-kvm@patchwork.kernel.org>;
 Fri,  8 Nov 2019 05:14:49 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (2048-bit key) header.d=google.com header.i=@google.com
 header.b="WAogCnEi"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726618AbfKHFOs (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Fri, 8 Nov 2019 00:14:48 -0500
Received: from mail-pg1-f201.google.com ([209.85.215.201]:36665 "EHLO
        mail-pg1-f201.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726103AbfKHFOs (ORCPT <rfc822;kvm@vger.kernel.org>);
        Fri, 8 Nov 2019 00:14:48 -0500
Received: by mail-pg1-f201.google.com with SMTP id h12so3850241pgd.3
        for <kvm@vger.kernel.org>; Thu, 07 Nov 2019 21:14:48 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:in-reply-to:message-id:mime-version:references:subject:from:to
         :cc;
        bh=XTXOT3PTQaYYqLr+YkwfmLP4vZijQPTV+yL5uM5usc8=;
        b=WAogCnEiNAjEpBBxEA04jsBppJNAzct4MnqswJ4df8s0CHWbVXwLLGkOzH9/XnK78l
         Ztq6FgnCus8aHki7P7WecVfTPt5EYarJ+OQAiWFpAEHZeA6vqBhKIihvLIuriWEKuEaM
         kHQmxUipNGVqi7QpO9OLUeRLrB4S36kGvGRG41JTdBn+Kfno6y0QIcDR+/Gf+JNvKI3O
         hCx61N6poBlNEua4/w6gUjkC1SQBrPkYu5dWVxc1D2XcxFiNk0rcjc3kZkwH8l+ovBaO
         OQ1UVHS4/vDfhNBKp8YpJDayzuChbeQB/xSgZcYTliFrBNdjGIiZ79NDbIPBW8y53xug
         BrGw==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:in-reply-to:message-id:mime-version
         :references:subject:from:to:cc;
        bh=XTXOT3PTQaYYqLr+YkwfmLP4vZijQPTV+yL5uM5usc8=;
        b=aQZXotbWrJdTxXGBAK7/oo+ipvp3pA3Fapocgjp3S9tSNfZVXkNSNNjig9Dt2Rulzk
         MOAktzWI2AgJ29tKms3ummwekh4zo+2kX3Ns7m04XyGu39RkFz3QQ0WboEcBJF+KHZgK
         7ZmK24nYb1GzNqxOCIJk4x5rTXsCbJEPe6C0mUyx5eZX+SFefjD4ADKP7BxqyHxuMOwS
         CjwZSeZTDDtVX0KOuwSecBFaGAIQTbUScgK6Rx3/av/NLcOQx6MMCwkrTwSG+WTh+kqV
         xCyLw5dHy9G0VFISp45Jh9aNSlKsF81000ZhAxZXghieYZpurELuYEcLm+uUHyWhvhNu
         hBcg==
X-Gm-Message-State: APjAAAVuMTjSbMGP+hjDjnLWV37rglIyvJNsHNxrz7cFTU6uCi1zh0HR
        7740D+mKnWC1UqQl/CBhPoOnSIInyiAv1ob8TaCXHuGB/Y5WKNnsbqmmnaIVgrUHc7tloAslrE2
        O9UMUm1eBoAv5fhbKB0nDj7dCa962vpZSUWtrlvOQ85YC5r58p6zgWVO/5mL/3vBB9wQ0
X-Google-Smtp-Source: 
 APXvYqwDF6ec+rIwZYgX2E84SGvt778JBkSQfQtR5T+gmWXNXHdoNP9EMbmLQxvGrjNi/yM9WpCEYhBrBKgEJDpw
X-Received: by 2002:a63:5508:: with SMTP id j8mr9132147pgb.97.1573190087463;
 Thu, 07 Nov 2019 21:14:47 -0800 (PST)
Date: Thu,  7 Nov 2019 21:14:36 -0800
In-Reply-To: <20191108051439.185635-1-aaronlewis@google.com>
Message-Id: <20191108051439.185635-2-aaronlewis@google.com>
Mime-Version: 1.0
References: <20191108051439.185635-1-aaronlewis@google.com>
X-Mailer: git-send-email 2.24.0.432.g9d3f5f5b63-goog
Subject: [PATCH v4 1/4] kvm: nested: Introduce read_and_check_msr_entry()
From: Aaron Lewis <aaronlewis@google.com>
To: kvm@vger.kernel.org
Cc: Jim Mattson <jmattson@google.com>,
        Paolo Bonzini <pbonzini@redhat.com>,
        Aaron Lewis <aaronlewis@google.com>,
        Liran Alon <liran.alon@oracle.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

Add the function read_and_check_msr_entry() which just pulls some code
out of nested_vmx_store_msr().  This will be useful as reusable code in
upcoming patches.

Reviewed-by: Liran Alon <liran.alon@oracle.com>
Reviewed-by: Jim Mattson <jmattson@google.com>
Signed-off-by: Aaron Lewis <aaronlewis@google.com>
---
 arch/x86/kvm/vmx/nested.c | 35 ++++++++++++++++++++++-------------
 1 file changed, 22 insertions(+), 13 deletions(-)

diff --git a/arch/x86/kvm/vmx/nested.c b/arch/x86/kvm/vmx/nested.c
index e76eb4f07f6c..7b058d7b9fcc 100644
--- a/arch/x86/kvm/vmx/nested.c
+++ b/arch/x86/kvm/vmx/nested.c
@@ -929,6 +929,26 @@ static u32 nested_vmx_load_msr(struct kvm_vcpu *vcpu, u64 gpa, u32 count)
 	return i + 1;
 }
 
+static bool read_and_check_msr_entry(struct kvm_vcpu *vcpu, u64 gpa, int i,
+				     struct vmx_msr_entry *e)
+{
+	if (kvm_vcpu_read_guest(vcpu,
+				gpa + i * sizeof(*e),
+				e, 2 * sizeof(u32))) {
+		pr_debug_ratelimited(
+			"%s cannot read MSR entry (%u, 0x%08llx)\n",
+			__func__, i, gpa + i * sizeof(*e));
+		return false;
+	}
+	if (nested_vmx_store_msr_check(vcpu, e)) {
+		pr_debug_ratelimited(
+			"%s check failed (%u, 0x%x, 0x%x)\n",
+			__func__, i, e->index, e->reserved);
+		return false;
+	}
+	return true;
+}
+
 static int nested_vmx_store_msr(struct kvm_vcpu *vcpu, u64 gpa, u32 count)
 {
 	u64 data;
@@ -940,20 +960,9 @@ static int nested_vmx_store_msr(struct kvm_vcpu *vcpu, u64 gpa, u32 count)
 		if (unlikely(i >= max_msr_list_size))
 			return -EINVAL;
 
-		if (kvm_vcpu_read_guest(vcpu,
-					gpa + i * sizeof(e),
-					&e, 2 * sizeof(u32))) {
-			pr_debug_ratelimited(
-				"%s cannot read MSR entry (%u, 0x%08llx)\n",
-				__func__, i, gpa + i * sizeof(e));
+		if (!read_and_check_msr_entry(vcpu, gpa, i, &e))
 			return -EINVAL;
-		}
-		if (nested_vmx_store_msr_check(vcpu, &e)) {
-			pr_debug_ratelimited(
-				"%s check failed (%u, 0x%x, 0x%x)\n",
-				__func__, i, e.index, e.reserved);
-			return -EINVAL;
-		}
+
 		if (kvm_get_msr(vcpu, e.index, &data)) {
 			pr_debug_ratelimited(
 				"%s cannot read MSR (%u, 0x%x)\n",

From patchwork Fri Nov  8 05:14:37 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Aaron Lewis <aaronlewis@google.com>
X-Patchwork-Id: 11234095
Return-Path: <SRS0=CHcm=ZA=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 2682F139A
	for <patchwork-kvm@patchwork.kernel.org>;
 Fri,  8 Nov 2019 05:14:53 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 041E021882
	for <patchwork-kvm@patchwork.kernel.org>;
 Fri,  8 Nov 2019 05:14:53 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (2048-bit key) header.d=google.com header.i=@google.com
 header.b="ZyTwqLk1"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726977AbfKHFOw (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Fri, 8 Nov 2019 00:14:52 -0500
Received: from mail-pg1-f202.google.com ([209.85.215.202]:34279 "EHLO
        mail-pg1-f202.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726103AbfKHFOv (ORCPT <rfc822;kvm@vger.kernel.org>);
        Fri, 8 Nov 2019 00:14:51 -0500
Received: by mail-pg1-f202.google.com with SMTP id w9so3846089pgl.1
        for <kvm@vger.kernel.org>; Thu, 07 Nov 2019 21:14:51 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:in-reply-to:message-id:mime-version:references:subject:from:to
         :cc;
        bh=4mSbfnV86WhUg0ov7lHDDNrLNgfz2FACKhYcwdyo8BE=;
        b=ZyTwqLk198xJ9tUzBV4NkJAH6A40D+S7auCTlZq63PemHSIlFsgVkNIV5eJ/BEBMTA
         Wn8KPVnfBOWOTkc72GTqjpF2OFXGo728ziiHTZGOITP3YVbVpc6LFfakD9uC5MmmO7Y9
         b5MT1mOFzdSREfQB1Uarn8H5eZxJ3LYaMWVYgk1HRrClguaaFcTD3QJ3vzmOALQlptw8
         3s3TFQ2GQ5U752uKx2PIPg77MAuArwoZkvoMbZSpYrqEpF5B0UP1M8iusaeX0TC85uXP
         oq6ckGs2RQZIj5KYLMasrgxA2fak9lX+2I/y+nSbGayo2Wqg7msHuLRpmh+HPT+COdhY
         1sgQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:in-reply-to:message-id:mime-version
         :references:subject:from:to:cc;
        bh=4mSbfnV86WhUg0ov7lHDDNrLNgfz2FACKhYcwdyo8BE=;
        b=LJIkkYdQDFWUuzVek2u+FWLm4DUruf0XVJKYnuGlpd1fH5bpL7rWkc0+Poovfc+i2z
         Wb6aDhHjsYu4V+J6hcMyxY0Gh/voa/k7kFj0E/4e+RPnOqXBQPP5A8jvvQqClsemwKZX
         XSYpOHPnTX1QV0mEXEMOMPvlgJS7VEby6nClRxeWWFOSnJpdWWgUSqq6IhbNvv1jOtfj
         9xWiA8s9/4ZwrZ5uZAk+STFANmcfySOKU8UQ4lWeAqzZqvixRJciXRPh9nAn74E1LKzX
         KBWEXWJFM5/lndsehxumUSDOoMb9+Etwxt8gRIA/30DYD5aUFM7Q1hDD/5ZIQD7sfYRA
         xeow==
X-Gm-Message-State: APjAAAVKip75vJISPtsSoEMBd7Fyf+gPzGIpCnH3xuWSNE9CvKkEydxb
        HbpexIepEE6XibEeTUtL5VK7gCcrhPTgm7LSmJ7TpHTd4kCifeRZqMSHJNhF/WASMR4sHhSlpLs
        QKCTqh8LQfzRRM3LPpoNt4qaEU5i6ehIS/+UFRSKt9DGzqqpfeC69+Maqpbf0X9fqOh9s
X-Google-Smtp-Source: 
 APXvYqwdrXHGdnO0ZMpUDBKpMINXBFA5c0PdI89KpN9rgD6G/qP6jwuDBF7F0hSWh4wPG707Kv01fh/hdz9MoTtc
X-Received: by 2002:a63:fb15:: with SMTP id o21mr9391038pgh.193.1573190090832;
 Thu, 07 Nov 2019 21:14:50 -0800 (PST)
Date: Thu,  7 Nov 2019 21:14:37 -0800
In-Reply-To: <20191108051439.185635-1-aaronlewis@google.com>
Message-Id: <20191108051439.185635-3-aaronlewis@google.com>
Mime-Version: 1.0
References: <20191108051439.185635-1-aaronlewis@google.com>
X-Mailer: git-send-email 2.24.0.432.g9d3f5f5b63-goog
Subject: [PATCH v4 2/4] kvm: vmx: Rename NR_AUTOLOAD_MSRS to NR_LOADSTORE_MSRS
From: Aaron Lewis <aaronlewis@google.com>
To: kvm@vger.kernel.org
Cc: Jim Mattson <jmattson@google.com>,
        Paolo Bonzini <pbonzini@redhat.com>,
        Aaron Lewis <aaronlewis@google.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

Rename NR_AUTOLOAD_MSRS to NR_LOADSTORE_MSRS.  This needs to be done
due to the addition of the MSR-autostore area that will be added in a
future patch.  After that the name AUTOLOAD will no longer make sense.

Reviewed-by: Jim Mattson <jmattson@google.com>
Signed-off-by: Aaron Lewis <aaronlewis@google.com>
---
 arch/x86/kvm/vmx/vmx.c | 4 ++--
 arch/x86/kvm/vmx/vmx.h | 4 ++--
 2 files changed, 4 insertions(+), 4 deletions(-)

diff --git a/arch/x86/kvm/vmx/vmx.c b/arch/x86/kvm/vmx/vmx.c
index e7970a2e8eae..d9afafc0e399 100644
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@ -940,8 +940,8 @@ static void add_atomic_switch_msr(struct vcpu_vmx *vmx, unsigned msr,
 	if (!entry_only)
 		j = find_msr(&m->host, msr);
 
-	if ((i < 0 && m->guest.nr == NR_AUTOLOAD_MSRS) ||
-		(j < 0 &&  m->host.nr == NR_AUTOLOAD_MSRS)) {
+	if ((i < 0 && m->guest.nr == NR_LOADSTORE_MSRS) ||
+		(j < 0 &&  m->host.nr == NR_LOADSTORE_MSRS)) {
 		printk_once(KERN_WARNING "Not enough msr switch entries. "
 				"Can't add msr %x\n", msr);
 		return;
diff --git a/arch/x86/kvm/vmx/vmx.h b/arch/x86/kvm/vmx/vmx.h
index bee16687dc0b..1dad8e5c8f86 100644
--- a/arch/x86/kvm/vmx/vmx.h
+++ b/arch/x86/kvm/vmx/vmx.h
@@ -22,11 +22,11 @@ extern u32 get_umwait_control_msr(void);
 
 #define X2APIC_MSR(r) (APIC_BASE_MSR + ((r) >> 4))
 
-#define NR_AUTOLOAD_MSRS 8
+#define NR_LOADSTORE_MSRS 8
 
 struct vmx_msrs {
 	unsigned int		nr;
-	struct vmx_msr_entry	val[NR_AUTOLOAD_MSRS];
+	struct vmx_msr_entry	val[NR_LOADSTORE_MSRS];
 };
 
 struct shared_msr_entry {

From patchwork Fri Nov  8 05:14:38 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Aaron Lewis <aaronlewis@google.com>
X-Patchwork-Id: 11234097
Return-Path: <SRS0=CHcm=ZA=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 6016F1515
	for <patchwork-kvm@patchwork.kernel.org>;
 Fri,  8 Nov 2019 05:14:56 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 3E5AD21D6C
	for <patchwork-kvm@patchwork.kernel.org>;
 Fri,  8 Nov 2019 05:14:56 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (2048-bit key) header.d=google.com header.i=@google.com
 header.b="a0IgFnUt"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1725769AbfKHFOz (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Fri, 8 Nov 2019 00:14:55 -0500
Received: from mail-ua1-f74.google.com ([209.85.222.74]:54737 "EHLO
        mail-ua1-f74.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726645AbfKHFOz (ORCPT <rfc822;kvm@vger.kernel.org>);
        Fri, 8 Nov 2019 00:14:55 -0500
Received: by mail-ua1-f74.google.com with SMTP id x2so1833817uaj.21
        for <kvm@vger.kernel.org>; Thu, 07 Nov 2019 21:14:54 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:in-reply-to:message-id:mime-version:references:subject:from:to
         :cc;
        bh=t9ntozjX65YwM0irxGvMCIbTKOnw1B1qw4N9v+V/Q1U=;
        b=a0IgFnUtkBRHfOvXtqUTSTzYwD7TtYSNYeaRYM77PbryGwk2e1e5RiOhs3hVcpODhQ
         SWidz4GF730RnLEKw509GbKTU1mqbFIeozX6vYrO3RjeWKecJIrpEAkoWHrlCDmxsPwZ
         Sy3V6wxRWIE2qCRU5EM87rXntn9ntvaATbYITdYuVZBSuaigkiDVMxaBQMOrVUhpIoaN
         tdQYpxu7nCedSZs0nyQBByaXK8uGwYuEHUsHHRZVdhJGtvzV039J/22kEtf0bSPMMv/7
         y+npJVEPMFfqDkzcZGWe3W6iPU3ykXf5nor29I7TwMdW/NopEVrH000ZWG3BMohldiI0
         pc8g==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:in-reply-to:message-id:mime-version
         :references:subject:from:to:cc;
        bh=t9ntozjX65YwM0irxGvMCIbTKOnw1B1qw4N9v+V/Q1U=;
        b=WxzlJnhoTLPRaIqOi2bl7WGfpUgEkruf0wozJ/IwX3sirWQ2mruysNoi7YK0dEEaht
         mF3IIte9mrMAnHVsx2ldgpgbPgcy98jnh/feS8B+7DL8VHM9/NTEC5fP1DEp9vlr6tj/
         c9VfG5nOG1gfXd2LRRrSXFMFwnFzh4MOQEffPSTV411j+1R90HFxxnF8lDYw8gdHNhhe
         iETfAE1tn9DOm2hB3TDoXi0DZi3Pr7mNeZK+YdSfrf8yxVHcf7GlbMFAFmrucRJ1oo6I
         dEfgdDFh8FdfkYod+GcwzEKraM7Tf2W+klSoczS3jB7gk7DmifIGobVBAR80cSHY7H8x
         9Dtg==
X-Gm-Message-State: APjAAAUwJ2YHT04mX2sss01PkJDn7EP5NC72jqt7RH+bEwD57FJT66bI
        4BWgW0TvZ2pvPLMLVE8K9/bvQJTYAQmHm3S82WmF8NPmnkkJLL5pcMlOFlxsxr9+Tm0zSO4sose
        S5QhV/Wl4sskDHofAYu+v9tEW817KMfxTXU/aJv7/HYQDPh1K0rol7OfZexHevEozlsJv
X-Google-Smtp-Source: 
 APXvYqyJIeiTKi48eTMLCGmyUWtX+04Gq9DovEpt3uUMWLCvmCYvD8+rrAOAmt3YyVSkg7OUvWQk5+BV5hJO578I
X-Received: by 2002:a9f:2304:: with SMTP id 4mr5436423uae.69.1573190093993;
 Thu, 07 Nov 2019 21:14:53 -0800 (PST)
Date: Thu,  7 Nov 2019 21:14:38 -0800
In-Reply-To: <20191108051439.185635-1-aaronlewis@google.com>
Message-Id: <20191108051439.185635-4-aaronlewis@google.com>
Mime-Version: 1.0
References: <20191108051439.185635-1-aaronlewis@google.com>
X-Mailer: git-send-email 2.24.0.432.g9d3f5f5b63-goog
Subject: [PATCH v4 3/4] kvm: vmx: Rename function find_msr() to
 vmx_find_msr_index()
From: Aaron Lewis <aaronlewis@google.com>
To: kvm@vger.kernel.org
Cc: Jim Mattson <jmattson@google.com>,
        Paolo Bonzini <pbonzini@redhat.com>,
        Aaron Lewis <aaronlewis@google.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

Rename function find_msr() to vmx_find_msr_index() in preparation for an
upcoming patch where we export it and use it in nested.c.

Reviewed-by: Jim Mattson <jmattson@google.com>
Signed-off-by: Aaron Lewis <aaronlewis@google.com>
---
 arch/x86/kvm/vmx/vmx.c | 10 +++++-----
 1 file changed, 5 insertions(+), 5 deletions(-)

diff --git a/arch/x86/kvm/vmx/vmx.c b/arch/x86/kvm/vmx/vmx.c
index d9afafc0e399..3fa836a5569a 100644
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@ -835,7 +835,7 @@ static void clear_atomic_switch_msr_special(struct vcpu_vmx *vmx,
 	vm_exit_controls_clearbit(vmx, exit);
 }
 
-static int find_msr(struct vmx_msrs *m, unsigned int msr)
+static int vmx_find_msr_index(struct vmx_msrs *m, u32 msr)
 {
 	unsigned int i;
 
@@ -869,7 +869,7 @@ static void clear_atomic_switch_msr(struct vcpu_vmx *vmx, unsigned msr)
 		}
 		break;
 	}
-	i = find_msr(&m->guest, msr);
+	i = vmx_find_msr_index(&m->guest, msr);
 	if (i < 0)
 		goto skip_guest;
 	--m->guest.nr;
@@ -877,7 +877,7 @@ static void clear_atomic_switch_msr(struct vcpu_vmx *vmx, unsigned msr)
 	vmcs_write32(VM_ENTRY_MSR_LOAD_COUNT, m->guest.nr);
 
 skip_guest:
-	i = find_msr(&m->host, msr);
+	i = vmx_find_msr_index(&m->host, msr);
 	if (i < 0)
 		return;
 
@@ -936,9 +936,9 @@ static void add_atomic_switch_msr(struct vcpu_vmx *vmx, unsigned msr,
 		wrmsrl(MSR_IA32_PEBS_ENABLE, 0);
 	}
 
-	i = find_msr(&m->guest, msr);
+	i = vmx_find_msr_index(&m->guest, msr);
 	if (!entry_only)
-		j = find_msr(&m->host, msr);
+		j = vmx_find_msr_index(&m->host, msr);
 
 	if ((i < 0 && m->guest.nr == NR_LOADSTORE_MSRS) ||
 		(j < 0 &&  m->host.nr == NR_LOADSTORE_MSRS)) {

From patchwork Fri Nov  8 05:14:39 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Aaron Lewis <aaronlewis@google.com>
X-Patchwork-Id: 11234099
Return-Path: <SRS0=CHcm=ZA=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 445141515
	for <patchwork-kvm@patchwork.kernel.org>;
 Fri,  8 Nov 2019 05:15:00 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 1936921882
	for <patchwork-kvm@patchwork.kernel.org>;
 Fri,  8 Nov 2019 05:15:00 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (2048-bit key) header.d=google.com header.i=@google.com
 header.b="D3o1bVvJ"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727017AbfKHFO7 (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Fri, 8 Nov 2019 00:14:59 -0500
Received: from mail-pl1-f202.google.com ([209.85.214.202]:54297 "EHLO
        mail-pl1-f202.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1726648AbfKHFO6 (ORCPT <rfc822;kvm@vger.kernel.org>);
        Fri, 8 Nov 2019 00:14:58 -0500
Received: by mail-pl1-f202.google.com with SMTP id a11so3426899plp.21
        for <kvm@vger.kernel.org>; Thu, 07 Nov 2019 21:14:58 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:in-reply-to:message-id:mime-version:references:subject:from:to
         :cc;
        bh=1ZDZaljAr+J9pCFCLmqq2EbZTKuXklrA+SPyJole690=;
        b=D3o1bVvJ6GIIeOFPdsKW46bYp3cNd7Xp5CRbRgvNYDrIMM4MvfGlmxXBghGjvewH12
         Jz3LNdw4r67xrjw/kVQX6DL1K/wNGZBvYfBLZaP1LGvtJ2TEDBItbmBYvhwBckgoEF+1
         BSqcUI2X48y8l5R/J4eAC8qDp350K3STss84mOzepFzjMt14VJTtsSdJPTjkDflHxMPY
         SrURzyFFJIEB4d2i64Z5EYq0e9bx48OoFy0rrawqyqJ/M7QrAAjXJ8Si4gSclswlZHrc
         iGjDkL1CPH9d/iprsIZoWN6A6mXVw6XYhVjdvlWtWizqjwHiuoRUzCY8WGXKcX0SUtmD
         C90A==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:in-reply-to:message-id:mime-version
         :references:subject:from:to:cc;
        bh=1ZDZaljAr+J9pCFCLmqq2EbZTKuXklrA+SPyJole690=;
        b=CC8jjq1GqR1Tzwxp2zNT+CqUhNIzoq6LO96TnOPYc6Vpg/KGP+KQ1cOwqVkeXM2Xrw
         PLf1xE56wymfKdB7AY8qRilW4BaeGSa945N+lE+DKpYCHtLTlCvAc5pqMboazxzWGUUa
         kaj6efwbexQ4q79JvjFD8gTOhmrygiVIhJprFmVaZWd7VZee09yrODWTJwWD2VL3FCYf
         nKpKdQjMudxXxysB71lUpXpLtMhbDkjnNbvtxd2qP/vLGm0gQy78nfs56jfwWCUPLsyH
         JUC9Sn0YngYN+Y/mE6CdGS/lYsR5ndReag+WPMjaghRRuo/a8yrIA1s2R5s8mLrBUq+l
         22cg==
X-Gm-Message-State: APjAAAXD9Al9WMwbuXPVXZGaA5sTy4P38B0lJWj9MNhBekKWQfPulPPx
        L9QzPlR6/LPXIcND8I6sXAcl3JwQqQ8XW8FRwyuPjt/HOlkDKnFV5GXklraxltMnsLwSvwk1zgg
        Uthr3607Shlyri7lL73QTJx/L982IOrk4tcKIW7vsu0xpHxYQOuOzBBMVBuHOd9fSmxRJ
X-Google-Smtp-Source: 
 APXvYqwOJZ44fodsxvEK74ybIB2A55WutrHeTLbg55HZaMaAWqRJoFD8s2+3ybMDQOWbN5m7oeM3PVXx+Zc/ySk7
X-Received: by 2002:a63:e148:: with SMTP id h8mr9119825pgk.297.1573190097241;
 Thu, 07 Nov 2019 21:14:57 -0800 (PST)
Date: Thu,  7 Nov 2019 21:14:39 -0800
In-Reply-To: <20191108051439.185635-1-aaronlewis@google.com>
Message-Id: <20191108051439.185635-5-aaronlewis@google.com>
Mime-Version: 1.0
References: <20191108051439.185635-1-aaronlewis@google.com>
X-Mailer: git-send-email 2.24.0.432.g9d3f5f5b63-goog
Subject: [PATCH v4 4/4] KVM: nVMX: Add support for capturing highest
 observable L2 TSC
From: Aaron Lewis <aaronlewis@google.com>
To: kvm@vger.kernel.org
Cc: Jim Mattson <jmattson@google.com>,
        Paolo Bonzini <pbonzini@redhat.com>,
        Aaron Lewis <aaronlewis@google.com>,
        Liran Alon <liran.alon@oracle.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

The L1 hypervisor may include the IA32_TIME_STAMP_COUNTER MSR in the
vmcs12 MSR VM-exit MSR-store area as a way of determining the highest
TSC value that might have been observed by L2 prior to VM-exit. The
current implementation does not capture a very tight bound on this
value.  To tighten the bound, add the IA32_TIME_STAMP_COUNTER MSR to the
vmcs02 VM-exit MSR-store area whenever it appears in the vmcs12 VM-exit
MSR-store area.  When L0 processes the vmcs12 VM-exit MSR-store area
during the emulation of an L2->L1 VM-exit, special-case the
IA32_TIME_STAMP_COUNTER MSR, using the value stored in the vmcs02
VM-exit MSR-store area to derive the value to be stored in the vmcs12
VM-exit MSR-store area.

Reviewed-by: Liran Alon <liran.alon@oracle.com>
Reviewed-by: Jim Mattson <jmattson@google.com>
Signed-off-by: Aaron Lewis <aaronlewis@google.com>
---
 arch/x86/kvm/vmx/nested.c | 101 +++++++++++++++++++++++++++++++++++---
 arch/x86/kvm/vmx/vmx.c    |   2 +-
 arch/x86/kvm/vmx/vmx.h    |   5 ++
 3 files changed, 101 insertions(+), 7 deletions(-)

diff --git a/arch/x86/kvm/vmx/nested.c b/arch/x86/kvm/vmx/nested.c
index 7b058d7b9fcc..2055f15cb007 100644
--- a/arch/x86/kvm/vmx/nested.c
+++ b/arch/x86/kvm/vmx/nested.c
@@ -929,6 +929,37 @@ static u32 nested_vmx_load_msr(struct kvm_vcpu *vcpu, u64 gpa, u32 count)
 	return i + 1;
 }
 
+static bool nested_vmx_get_vmexit_msr_value(struct kvm_vcpu *vcpu,
+					    u32 msr_index,
+					    u64 *data)
+{
+	struct vcpu_vmx *vmx = to_vmx(vcpu);
+
+	/*
+	 * If the L0 hypervisor stored a more accurate value for the TSC that
+	 * does not include the time taken for emulation of the L2->L1
+	 * VM-exit in L0, use the more accurate value.
+	 */
+	if (msr_index == MSR_IA32_TSC) {
+		int index = vmx_find_msr_index(&vmx->msr_autostore.guest,
+					       MSR_IA32_TSC);
+
+		if (index >= 0) {
+			u64 val = vmx->msr_autostore.guest.val[index].value;
+
+			*data = kvm_read_l1_tsc(vcpu, val);
+			return true;
+		}
+	}
+
+	if (kvm_get_msr(vcpu, msr_index, data)) {
+		pr_debug_ratelimited("%s cannot read MSR (0x%x)\n", __func__,
+			msr_index);
+		return false;
+	}
+	return true;
+}
+
 static bool read_and_check_msr_entry(struct kvm_vcpu *vcpu, u64 gpa, int i,
 				     struct vmx_msr_entry *e)
 {
@@ -963,12 +994,9 @@ static int nested_vmx_store_msr(struct kvm_vcpu *vcpu, u64 gpa, u32 count)
 		if (!read_and_check_msr_entry(vcpu, gpa, i, &e))
 			return -EINVAL;
 
-		if (kvm_get_msr(vcpu, e.index, &data)) {
-			pr_debug_ratelimited(
-				"%s cannot read MSR (%u, 0x%x)\n",
-				__func__, i, e.index);
+		if (!nested_vmx_get_vmexit_msr_value(vcpu, e.index, &data))
 			return -EINVAL;
-		}
+
 		if (kvm_vcpu_write_guest(vcpu,
 					 gpa + i * sizeof(e) +
 					     offsetof(struct vmx_msr_entry, value),
@@ -982,6 +1010,60 @@ static int nested_vmx_store_msr(struct kvm_vcpu *vcpu, u64 gpa, u32 count)
 	return 0;
 }
 
+static bool nested_msr_store_list_has_msr(struct kvm_vcpu *vcpu, u32 msr_index)
+{
+	struct vmcs12 *vmcs12 = get_vmcs12(vcpu);
+	u32 count = vmcs12->vm_exit_msr_store_count;
+	u64 gpa = vmcs12->vm_exit_msr_store_addr;
+	struct vmx_msr_entry e;
+	u32 i;
+
+	for (i = 0; i < count; i++) {
+		if (!read_and_check_msr_entry(vcpu, gpa, i, &e))
+			return false;
+
+		if (e.index == msr_index)
+			return true;
+	}
+	return false;
+}
+
+static void prepare_vmx_msr_autostore_list(struct kvm_vcpu *vcpu,
+					   u32 msr_index)
+{
+	struct vcpu_vmx *vmx = to_vmx(vcpu);
+	struct vmx_msrs *autostore = &vmx->msr_autostore.guest;
+	bool in_vmcs12_store_list;
+	int msr_autostore_index;
+	bool in_autostore_list;
+	int last;
+
+	msr_autostore_index = vmx_find_msr_index(autostore, msr_index);
+	in_autostore_list = msr_autostore_index >= 0;
+	in_vmcs12_store_list = nested_msr_store_list_has_msr(vcpu, msr_index);
+
+	if (in_vmcs12_store_list && !in_autostore_list) {
+		if (autostore->nr == NR_LOADSTORE_MSRS) {
+			/*
+			 * Emulated VMEntry does not fail here.  Instead a less
+			 * accurate value will be returned by
+			 * nested_vmx_get_vmexit_msr_value() using kvm_get_msr()
+			 * instead of reading the value from the vmcs02 VMExit
+			 * MSR-store area.
+			 */
+			pr_warn_ratelimited(
+				"Not enough msr entries in msr_autostore.  Can't add msr %x\n",
+				msr_index);
+			return;
+		}
+		last = autostore->nr++;
+		autostore->val[last].index = msr_index;
+	} else if (!in_vmcs12_store_list && in_autostore_list) {
+		last = --autostore->nr;
+		autostore->val[msr_autostore_index] = autostore->val[last];
+	}
+}
+
 static bool nested_cr3_valid(struct kvm_vcpu *vcpu, unsigned long val)
 {
 	unsigned long invalid_mask;
@@ -2027,7 +2109,7 @@ static void prepare_vmcs02_constant_state(struct vcpu_vmx *vmx)
 	 * addresses are constant (for vmcs02), the counts can change based
 	 * on L2's behavior, e.g. switching to/from long mode.
 	 */
-	vmcs_write32(VM_EXIT_MSR_STORE_COUNT, 0);
+	vmcs_write64(VM_EXIT_MSR_STORE_ADDR, __pa(vmx->msr_autostore.guest.val));
 	vmcs_write64(VM_EXIT_MSR_LOAD_ADDR, __pa(vmx->msr_autoload.host.val));
 	vmcs_write64(VM_ENTRY_MSR_LOAD_ADDR, __pa(vmx->msr_autoload.guest.val));
 
@@ -2294,6 +2376,13 @@ static void prepare_vmcs02_rare(struct vcpu_vmx *vmx, struct vmcs12 *vmcs12)
 		vmcs_write64(EOI_EXIT_BITMAP3, vmcs12->eoi_exit_bitmap3);
 	}
 
+	/*
+	 * Make sure the msr_autostore list is up to date before we set the
+	 * count in the vmcs02.
+	 */
+	prepare_vmx_msr_autostore_list(&vmx->vcpu, MSR_IA32_TSC);
+
+	vmcs_write32(VM_EXIT_MSR_STORE_COUNT, vmx->msr_autostore.guest.nr);
 	vmcs_write32(VM_EXIT_MSR_LOAD_COUNT, vmx->msr_autoload.host.nr);
 	vmcs_write32(VM_ENTRY_MSR_LOAD_COUNT, vmx->msr_autoload.guest.nr);
 
diff --git a/arch/x86/kvm/vmx/vmx.c b/arch/x86/kvm/vmx/vmx.c
index 3fa836a5569a..a7fd70db0b1e 100644
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@ -835,7 +835,7 @@ static void clear_atomic_switch_msr_special(struct vcpu_vmx *vmx,
 	vm_exit_controls_clearbit(vmx, exit);
 }
 
-static int vmx_find_msr_index(struct vmx_msrs *m, u32 msr)
+int vmx_find_msr_index(struct vmx_msrs *m, u32 msr)
 {
 	unsigned int i;
 
diff --git a/arch/x86/kvm/vmx/vmx.h b/arch/x86/kvm/vmx/vmx.h
index 1dad8e5c8f86..673330e528e8 100644
--- a/arch/x86/kvm/vmx/vmx.h
+++ b/arch/x86/kvm/vmx/vmx.h
@@ -230,6 +230,10 @@ struct vcpu_vmx {
 		struct vmx_msrs host;
 	} msr_autoload;
 
+	struct msr_autostore {
+		struct vmx_msrs guest;
+	} msr_autostore;
+
 	struct {
 		int vm86_active;
 		ulong save_rflags;
@@ -334,6 +338,7 @@ void vmx_set_virtual_apic_mode(struct kvm_vcpu *vcpu);
 struct shared_msr_entry *find_msr_entry(struct vcpu_vmx *vmx, u32 msr);
 void pt_update_intercept_for_msr(struct vcpu_vmx *vmx);
 void vmx_update_host_rsp(struct vcpu_vmx *vmx, unsigned long host_rsp);
+int vmx_find_msr_index(struct vmx_msrs *m, u32 msr);
 
 #define POSTED_INTR_ON  0
 #define POSTED_INTR_SN  1
